# Image-Generation-Papers
A collection of latest papers for image generation (From 2019)

Mainly focus on conditional generation with different context.


## Context: Layerout / Semantic Map

| Model| Paper| Conference| Paper Link | Code Link | Comments|
| ---- | ---- | ----------| ---------- | ----------| -----------------|
| SPADE| Semantic Image Synthesis with Spatially-Adaptive Normalization| CVPR 2019 (Oral)| [1903.07291](https://arxiv.org/abs/1903.07291) |[NVlabs/SPADE](https://github.com/NVlabs/SPADE)|A normalization layer to avoid washing away sementic information|
|Layout2Im| Image Generation from Layout | CVPR 2019|[1811.11389](https://arxiv.org/abs/1811.11389)| | |
|Seg2vid| Video Generation from Single Semantic Label Map | CVPR 2019| [1903.04480](https://arxiv.org/abs/1903.04480)|[junting/seg2vid](https://github.com/junting/seg2vid/tree/master)| |



## Context: Text

| Model| Paper| Conference| Paper Link | Code Link | Comments|
| ---- | ---- | ----------| ---------- | ----------| -----------------|
| MirrorGAN| MirrorGAN: Learning Text-to-image Generation by Redescription| CVPR 2019 | [1903.05854](https://arxiv.org/abs/1903.05854) ||Text-to-image-to-text|
| ObjectGAN| Object-driven Text-to-Image Synthesis via Adversarial Training| CVPR 2019 | [1902.10740](https://arxiv.org/abs/1902.10740) ||object-driven + semantic layerout|
| StoryGAN| StoryGAN: A Sequential Conditional GAN for Story Visualization| CVPR 2019 | [1812.02784](https://arxiv.org/abs/1812.02784) |[yitong91/StoryGAN](https://github.com/yitong91/StoryGAN )|story-to-image-sequence generation|
|Text2Scene| Text2Scene: Generating Compositional Scenes from Textual Descriptions| CVPR 2019| [1809.01110](https://arxiv.org/abs/1809.01110 )|[yitong91/Text2Image](https://github.com/uvavision/Text2Image) | |
